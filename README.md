# Throat Mic Recording Tool & Dataset

A high-quality dataset and recording tool for fine-tuning Whisper using throat microphone recordings. This dataset is specifically designed for training speech recognition models on throat microphone input.

## Dataset Characteristics

- **Audio Format**: 16kHz mono WAV files
- **Duration**: Each recording is approximately 10 seconds
- **Recording Device**: Throat microphone (laryngophone)
- **Language**: English
- **Total Recordings**: 499 utterances
- **Total Duration**: ~83 minutes
- **Audio Quality**: High-quality recordings with consistent volume levels and minimal background noise

### Sentence Characteristics

The dataset uses carefully selected sentences that are:
- Complex enough for meaningful speech recognition training (12-25 words)
- Include proper grammar and punctuation
- Contain a mix of statement types (declarations, questions, etc.)
- Include natural language patterns and varied vocabulary
- Balanced in terms of phonetic content

### Dataset Format

The dataset follows the standard format required for Whisper fine-tuning:
```
data/
â”œâ”€â”€ recordings/           # WAV audio files (16kHz mono)
â”‚   â””â”€â”€ *.wav            # Format: {index}_{text_preview}.wav
â””â”€â”€ metadata/
    â””â”€â”€ metadata.csv     # Format: audio_filepath,text,duration
```

## Features

### Recording Tool
- ğŸ¤ Easy-to-use recording interface
- ğŸ“ Automatic prompt management
- âœ¨ Proper audio format for Whisper (16kHz, mono)
- ğŸ”„ Progress saving and session management
- ğŸ“Š Dataset quality analysis
- ğŸ” Real-time audio level monitoring
- âš¡ Clipping detection
- ğŸµ Playback verification

### Dataset Management
- ğŸ”„ Automatic synchronization with Hugging Face
- ğŸ“¥ Smart dataset downloading with duplicate detection
- ğŸ“¤ Efficient dataset uploading with change tracking
- ğŸ§¹ Duplicate cleanup functionality
- ğŸ“ Automatic dataset card management
- âœ… Data validation and quality checks

## Setup

1. Create and activate a Python 3.9+ virtual environment:
```bash
python3 -m venv .venv
source .venv/bin/activate
```

2. Install dependencies using uv (recommended) or pip:
```bash
# Using uv (faster)
uv pip install -r requirements.txt

# Using pip
pip install -r requirements.txt
```

3. Set up Hugging Face token (for dataset management):
```bash
# Add to your shell configuration (e.g., .zshrc, .bashrc)
export HF_TOKEN="your_hugging_face_token"
```

## Usage

### Recording
```bash
# Start recording session
python record_audio.py

# List available audio devices
python record_audio.py --list-devices

# Analyze dataset quality
python record_audio.py --analyze --quality

# Check dataset coverage
python record_audio.py --analyze --coverage
```

### Dataset Management
```bash
# Download dataset (automatically handles duplicates)
python download_dataset.py

# Upload to Hugging Face (only uploads new/changed files)
python upload_dataset.py

# Clean up duplicates in the dataset
python upload_dataset.py --cleanup

# Use custom repository
python download_dataset.py --repo-id custom/repo
python upload_dataset.py --repo-id custom/repo
```

### Advanced Options
```bash
# Specify custom metadata file location
--metadata path/to/metadata.csv

# Use different dataset card
--dataset-card path/to/card.md

# Provide Hugging Face token directly
--token YOUR_TOKEN
```

## Dataset Quality Control

Each recording undergoes several quality checks:
1. Audio level monitoring during recording
2. Clipping detection
3. Playback verification
4. Option to re-record if quality is unsatisfactory
5. Automatic validation during dataset upload

## License

MIT License - see LICENSE file for details. 